{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c17136d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Importar dependências necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6922d3c3",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import zipfile \n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc464365",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> A função abaixo será utilizada para verificar no DataFrame: \n",
    "> 1. A quantidade de linhas e colunas;\n",
    "> 2. A quantidade e o percentual de ***registros ausentes*** para cada coluna; \n",
    "> 3. A quantidade de ***registros duplicados***  existentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc6fc51e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def verificarAusentesDuplicados(data):\n",
    "    \"\"\"\n",
    "    Verifica a quantidade de linhas e de colunas do dataset, retorna a quantidade e o percentual \n",
    "    de valores ausentes para cada coluna do DataFrame e verifica a existência de registros duplicados.\n",
    "    \n",
    "    Parâmetros:\n",
    "    data -- DataFrame do pandas a ser verificado\n",
    "    \"\"\"\n",
    "    print(f\"O dataset tem {data.shape[0]} linhas e {data.shape[1]} colunas.\")\n",
    "    print(\"-\"*50+f\"\\nTotal de colunas com registros ausentes {data.isnull().any().sum()}\\n\")\n",
    "    print(\"Registros ausentes por coluna:\")  \n",
    "    for coluna in data.columns:\n",
    "        total_ausentes = data[coluna].isnull().sum()\n",
    "        percentual_ausentes = (total_ausentes / data.shape[0]) * 100\n",
    "        print(f\"> {coluna}, ausentes: {total_ausentes} ({percentual_ausentes:.2f}%)\")\n",
    "    \n",
    "    print(\"-\"*50+f\"\\nTotal de registros duplicados {data.duplicated().sum()}\\n\"+\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47de032",
   "metadata": {},
   "source": [
    "### Covid dataset\n",
    "> Disponível em: [Ministério da Saúde](https://www.gov.br/saude/pt-br/composicao/seidigi/demas/covid19 \"Fonte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc95a0",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f836f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"..\",\"data\",\"raw\")\n",
    "output_data_path = os.path.join(\"..\",\"data\", \"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30085c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo HIST_PAINEL_COVIDBR_21jun2023.zip descompactado no diretório: ..\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "#zip_file_name = f\"HIST_PAINEL_COVIDBR_{dt.now().strftime('%d%b%Y')}.zip\"\n",
    "zip_file_name = \"HIST_PAINEL_COVIDBR_21jun2023.zip\"\n",
    "zip_data_path = os.path.join(data_path, zip_file_name)\n",
    "\n",
    "with zipfile.ZipFile(zip_data_path, 'r') as data_zip:\n",
    "    data_zip.extractall(data_path)\n",
    "\n",
    "print(f\"Arquivo {zip_file_name} descompactado no diretório: {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6601183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6642526 entries, 0 to 966467\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   regiao                  object \n",
      " 1   estado                  object \n",
      " 2   municipio               object \n",
      " 3   coduf                   int64  \n",
      " 4   codmun                  float64\n",
      " 5   codRegiaoSaude          float64\n",
      " 6   nomeRegiaoSaude         object \n",
      " 7   data                    object \n",
      " 8   semanaEpi               int64  \n",
      " 9   populacaoTCU2019        float64\n",
      " 10  casosAcumulado          float64\n",
      " 11  casosNovos              int64  \n",
      " 12  obitosAcumulado         int64  \n",
      " 13  obitosNovos             int64  \n",
      " 14  Recuperadosnovos        float64\n",
      " 15  emAcompanhamentoNovos   float64\n",
      " 16  interior/metropolitana  float64\n",
      "dtypes: float64(7), int64(5), object(5)\n",
      "memory usage: 912.2+ MB\n"
     ]
    }
   ],
   "source": [
    "file_name=\"HIST_PAINEL_*.csv\"\n",
    "file_path = os.path.join(data_path, file_name)\n",
    "files = sorted(glob(file_path))\n",
    "covid_data = pd.concat((pd.read_csv(file, sep=\";\") for file in files))\n",
    "covid_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a20e2639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataset tem 6642526 linhas e 17 colunas.\n",
      "--------------------------------------------------\n",
      "Total de colunas com registros ausentes 9\n",
      "\n",
      "Registros ausentes por coluna:\n",
      "> regiao, ausentes: 0 (0.00%)\n",
      "> estado, ausentes: 1213 (0.02%)\n",
      "> municipio, ausentes: 58786 (0.88%)\n",
      "> coduf, ausentes: 0 (0.00%)\n",
      "> codmun, ausentes: 33964 (0.51%)\n",
      "> codRegiaoSaude, ausentes: 58786 (0.88%)\n",
      "> nomeRegiaoSaude, ausentes: 58786 (0.88%)\n",
      "> data, ausentes: 0 (0.00%)\n",
      "> semanaEpi, ausentes: 0 (0.00%)\n",
      "> populacaoTCU2019, ausentes: 24822 (0.37%)\n",
      "> casosAcumulado, ausentes: 0 (0.00%)\n",
      "> casosNovos, ausentes: 0 (0.00%)\n",
      "> obitosAcumulado, ausentes: 0 (0.00%)\n",
      "> obitosNovos, ausentes: 0 (0.00%)\n",
      "> Recuperadosnovos, ausentes: 6641314 (99.98%)\n",
      "> emAcompanhamentoNovos, ausentes: 6641314 (99.98%)\n",
      "> interior/metropolitana, ausentes: 58786 (0.88%)\n",
      "--------------------------------------------------\n",
      "Total de registros duplicados 0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "verificarAusentesDuplicados(covid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21c77e",
<<<<<<< HEAD
   "metadata": {},
=======
   "metadata": {
    "heading_collapsed": true
   },
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
   "source": [
    "##### Registros ausentes\n",
    "> A presença de registros ausentes está relacionada às estatísticas generalizadas para o país, não agregadas por Macroregião, Estado e municípios. Nesse contexto, é fundamental ter cautela ao interpretar os registros ausentes nas colunas mencionadas, uma vez que eles estão relacionados aos dados generalizados para o Brasil e podem não refletir diretamente as informações específicas por região ou município.<br><br>É importante destacar que, embora haja registros ausentes nessas estatísticas generalizadas, os dados subsequentes no dataframe podem fornecer informações mais detalhadas e específicas por Macroregião, Estado e municípios. Portanto, é recomendado considerar as informações adicionais disponíveis nas demais linhas do dataframe para uma análise mais completa e precisa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91faee33",
   "metadata": {},
   "source": [
    "#### Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb0ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificar coluna data para o formato datetime64[ns]\n",
    "covid_data[\"data\"]= pd.to_datetime(covid_data[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "526712b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checar o dtype de cada coluna e modificá-los para inteiro se forem float\n",
    "for col in covid_data.columns:\n",
    "    if covid_data[col].dtype == 'float':\n",
    "        covid_data[col] = covid_data[col].fillna(0).astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e1d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar os dados não agregados por Macroregiao, Estado e município\n",
    "brasil_df = covid_data[covid_data[\"regiao\"] == \"Brasil\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62f683e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1213 entries, 0 to 1212\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   data                   1213 non-null   datetime64[ns]\n",
      " 1   casosAcumulado         1213 non-null   int64         \n",
      " 2   casosNovos             1213 non-null   int64         \n",
      " 3   obitosAcumulado        1213 non-null   int64         \n",
      " 4   obitosNovos            1213 non-null   int64         \n",
      " 5   Recuperadosnovos       1213 non-null   int64         \n",
      " 6   emAcompanhamentoNovos  1213 non-null   int64         \n",
      "dtypes: datetime64[ns](1), int64(6)\n",
      "memory usage: 66.5 KB\n"
     ]
    }
   ],
   "source": [
    "# Dropar as colunas desnecessárisa do DataFrame brasil_df\n",
    "br_df_drop_cols = ['regiao',\n",
    "                   'estado',\n",
    "                   'municipio',\n",
    "                   'coduf',\n",
    "                   'codmun',\n",
    "                   'codRegiaoSaude',\n",
    "                   'semanaEpi',\n",
    "                   'populacaoTCU2019',\n",
    "                   'nomeRegiaoSaude',\n",
    "                   \"interior/metropolitana\"]\n",
    "\n",
    "brasil_df = brasil_df.drop(br_df_drop_cols, axis=1).reset_index(drop=True)\n",
    "brasil_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dcf9ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataset tem 1213 linhas e 7 colunas.\n",
      "--------------------------------------------------\n",
      "Total de colunas com registros ausentes 0\n",
      "\n",
      "Registros ausentes por coluna:\n",
      "> data, ausentes: 0 (0.00%)\n",
      "> casosAcumulado, ausentes: 0 (0.00%)\n",
      "> casosNovos, ausentes: 0 (0.00%)\n",
      "> obitosAcumulado, ausentes: 0 (0.00%)\n",
      "> obitosNovos, ausentes: 0 (0.00%)\n",
      "> Recuperadosnovos, ausentes: 0 (0.00%)\n",
      "> emAcompanhamentoNovos, ausentes: 0 (0.00%)\n",
      "--------------------------------------------------\n",
      "Total de registros duplicados 0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "verificarAusentesDuplicados(brasil_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
<<<<<<< HEAD
=======
   "id": "50cabf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o DataFrame resultante em um arquivo CSV\n",
    "brasil_df.to_csv(\n",
    "    #os.path.join(output_data_path, 'covid_br_dataset.csv'), index=False, date_format='%d/%m/%Y'\n",
    "    os.path.join(output_data_path, 'covid_br_dataset.csv'), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
   "id": "78b441df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar os dados agregados por Macroregiao, Estado e município\n",
    "estados_df = covid_data.loc[covid_data['regiao']!=\"Brasil\"]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 14,
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
   "id": "2bbe361d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropar as colunas desnecessárisa do DataFrame estados_df\n",
    "estados_df_drop_cols = [\n",
    "    'municipio',\n",
    "    'codmun',\n",
    "    'codRegiaoSaude',\n",
    "    'semanaEpi',\n",
    "    'nomeRegiaoSaude'\n",
    "]\n",
    "\n",
    "estados_df = estados_df.drop(estados_df_drop_cols, axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 15,
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
   "id": "bf241116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário com os códigos de UF e nomes dos estados correspondentes\n",
    "codigo_uf = {\n",
    "    11: 'Rondônia',\n",
    "    12: 'Acre',\n",
    "    13: 'Amazonas',\n",
    "    14: 'Roraima',\n",
    "    15: 'Pará',\n",
    "    16: 'Amapá',\n",
    "    17: 'Tocantins',\n",
    "    21: 'Maranhão',\n",
    "    22: 'Piauí',\n",
    "    23: 'Ceará',\n",
    "    24: 'Rio Grande do Norte',\n",
    "    25: 'Paraíba',\n",
    "    26: 'Pernambuco',\n",
    "    27: 'Alagoas',\n",
    "    28: 'Sergipe',\n",
    "    29: 'Bahia',\n",
    "    31: 'Minas Gerais',\n",
    "    32: 'Espírito Santo',\n",
    "    33: 'Rio de Janeiro',\n",
    "    35: 'São Paulo',\n",
    "    41: 'Paraná',\n",
    "    42: 'Santa Catarina',\n",
    "    43: 'Rio Grande do Sul',\n",
    "    50: 'Mato Grosso do Sul',\n",
    "    51: 'Mato Grosso',\n",
    "    52: 'Goiás',\n",
    "    53: 'Distrito Federal'\n",
    "}\n",
    "# Substituir os valores inteiros pelos nomes dos estados\n",
    "estados_df['coduf'] = estados_df['coduf'].map(codigo_uf)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 16,
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
   "id": "bf63d83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6641313 entries, 0 to 6641312\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Dtype         \n",
      "---  ------                  -----         \n",
      " 0   regiao                  object        \n",
      " 1   siglaUF                 object        \n",
      " 2   estado                  object        \n",
      " 3   data                    datetime64[ns]\n",
      " 4   populacaoTCU2019        int64         \n",
      " 5   casosAcumulado          int64         \n",
      " 6   casosNovos              int64         \n",
      " 7   obitosAcumulado         int64         \n",
      " 8   obitosNovos             int64         \n",
      " 9   Recuperadosnovos        int64         \n",
      " 10  emAcompanhamentoNovos   int64         \n",
      " 11  interior/metropolitana  int64         \n",
      "dtypes: datetime64[ns](1), int64(8), object(3)\n",
      "memory usage: 608.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Renomear a coluna \"coduf\" para \"siglaUF\"\n",
    "estados_df.rename(columns={'estado': 'siglaUF', \"coduf\":\"estado\"}, inplace=True)\n",
    "estados_df.info()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 17,
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
   "id": "53ec32b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataset tem 6641313 linhas e 12 colunas.\n",
      "--------------------------------------------------\n",
      "Total de colunas com registros ausentes 0\n",
      "\n",
      "Registros ausentes por coluna:\n",
      "> regiao, ausentes: 0 (0.00%)\n",
      "> siglaUF, ausentes: 0 (0.00%)\n",
      "> estado, ausentes: 0 (0.00%)\n",
      "> data, ausentes: 0 (0.00%)\n",
      "> populacaoTCU2019, ausentes: 0 (0.00%)\n",
      "> casosAcumulado, ausentes: 0 (0.00%)\n",
      "> casosNovos, ausentes: 0 (0.00%)\n",
      "> obitosAcumulado, ausentes: 0 (0.00%)\n",
      "> obitosNovos, ausentes: 0 (0.00%)\n",
      "> Recuperadosnovos, ausentes: 0 (0.00%)\n",
      "> emAcompanhamentoNovos, ausentes: 0 (0.00%)\n",
      "> interior/metropolitana, ausentes: 0 (0.00%)\n",
      "--------------------------------------------------\n",
      "Total de registros duplicados 2502\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "verificarAusentesDuplicados(estados_df)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 18,
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
   "id": "ae2db972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regiao</th>\n",
       "      <th>siglaUF</th>\n",
       "      <th>estado</th>\n",
       "      <th>data</th>\n",
       "      <th>populacaoTCU2019</th>\n",
       "      <th>casosAcumulado</th>\n",
       "      <th>casosNovos</th>\n",
       "      <th>obitosAcumulado</th>\n",
       "      <th>obitosNovos</th>\n",
       "      <th>Recuperadosnovos</th>\n",
       "      <th>emAcompanhamentoNovos</th>\n",
       "      <th>interior/metropolitana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2490846</th>\n",
       "      <td>Sul</td>\n",
       "      <td>RS</td>\n",
       "      <td>Rio Grande do Sul</td>\n",
       "      <td>2021-01-24</td>\n",
       "      <td>2242</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490847</th>\n",
       "      <td>Sul</td>\n",
       "      <td>RS</td>\n",
       "      <td>Rio Grande do Sul</td>\n",
       "      <td>2021-01-25</td>\n",
       "      <td>2242</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133351</th>\n",
       "      <td>Sudeste</td>\n",
       "      <td>MG</td>\n",
       "      <td>Minas Gerais</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>3150</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133352</th>\n",
       "      <td>Sudeste</td>\n",
       "      <td>MG</td>\n",
       "      <td>Minas Gerais</td>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>3150</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4541429</th>\n",
       "      <td>Sul</td>\n",
       "      <td>RS</td>\n",
       "      <td>Rio Grande do Sul</td>\n",
       "      <td>2022-02-06</td>\n",
       "      <td>2242</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          regiao siglaUF             estado       data  populacaoTCU2019   \n",
       "2490846      Sul      RS  Rio Grande do Sul 2021-01-24              2242  \\\n",
       "2490847      Sul      RS  Rio Grande do Sul 2021-01-25              2242   \n",
       "3133351  Sudeste      MG       Minas Gerais 2021-07-01              3150   \n",
       "3133352  Sudeste      MG       Minas Gerais 2021-07-02              3150   \n",
       "4541429      Sul      RS  Rio Grande do Sul 2022-02-06              2242   \n",
       "\n",
       "         casosAcumulado  casosNovos  obitosAcumulado  obitosNovos   \n",
       "2490846              92           0                1            0  \\\n",
       "2490847              92           0                1            0   \n",
       "3133351             164           0                7            0   \n",
       "3133352             164           0                7            0   \n",
       "4541429             450           0                4            0   \n",
       "\n",
       "         Recuperadosnovos  emAcompanhamentoNovos  interior/metropolitana  \n",
       "2490846                 0                      0                       0  \n",
       "2490847                 0                      0                       0  \n",
       "3133351                 0                      0                       0  \n",
       "3133352                 0                      0                       0  \n",
       "4541429                 0                      0                       0  "
      ]
     },
<<<<<<< HEAD
     "execution_count": 17,
=======
     "execution_count": 18,
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_duplicados = estados_df[estados_df.duplicated()]\n",
    "dados_duplicados.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a484113",
<<<<<<< HEAD
   "metadata": {},
=======
   "metadata": {
    "heading_collapsed": true
   },
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
   "source": [
    "##### Registros duplicados\n",
    "> A presença de registros duplicados está relacionada ao fato de existirem datas diferentes com a mesma quantidade de óbitos e casos. Ou seja, não houve novos registros na data, porém decidiu-se por manter os dados uma vez que os valores da coluna ***populcaoTCU2019*** podem interferir posteriormente no cálculo das taxas de mortalidade e incidência. Levando em consideração a data, por sua vez, é importante mantê-las para evitar futuros bugs com os filtros que serão utilizados no app."
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "id": "ef4e80f6",
   "metadata": {},
   "source": [
    "#### Salvar Dataframes resultantes em arquivos CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "382a9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "brasil_df.to_csv(\n",
    "    #os.path.join(output_data_path, 'covid_br_dataset.csv'), index=False, date_format='%d/%m/%Y'\n",
    "    os.path.join(output_data_path, 'covid_br_dataset.csv'), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82adbaf9",
   "metadata": {},
   "outputs": [],
   "source": [
=======
   "cell_type": "code",
   "execution_count": null,
   "id": "88b1f42a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Salvar o DataFrame resultante em um arquivo CSV\n",
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
    "estados_df.to_csv(\n",
    "    #os.path.join(output_data_path, 'covid_estados_dataset.csv'), index=False, date_format='%d/%m/%Y'\n",
    "    os.path.join(output_data_path, 'covid_estados_dataset.csv'), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9240144b",
   "metadata": {},
   "source": [
    "### Índices Socioeconômicos \n",
    "> Disponível em: [IBGE - PNAD Contínua](https://www.ibge.gov.br/estatisticas/sociais/populacao.html \"Fonte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5491e2",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 19,
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
   "id": "d501eccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo indicesSocioeconomicos.zip descompactado no diretório: ..\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "zip_file_name = \"indicesSocioeconomicos.zip\"\n",
    "zip_data_path = os.path.join(data_path, zip_file_name)\n",
    "\n",
    "with zipfile.ZipFile(zip_data_path, 'r') as data_zip:\n",
    "    data_zip.extractall(data_path)\n",
    "\n",
    "print(f\"Arquivo {zip_file_name} descompactado no diretório: {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 20,
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
   "id": "c48fbe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27 entries, 0 to 26\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   siglaUF               27 non-null     object \n",
      " 1   estado                27 non-null     object \n",
      " 2   rendimentoDomiciliar  27 non-null     int64  \n",
      " 3   despesaMediaSaude     27 non-null     float64\n",
      " 4   indiceGini            27 non-null     float64\n",
      " 5   indicePalma           27 non-null     float64\n",
      " 6   area2019              27 non-null     float64\n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "file_name=\"indices_Socioeconomicos.csv\"\n",
    "file_path = os.path.join(data_path, file_name)\n",
    "indices_data = (pd.read_csv(file_path, sep=\";\"))\n",
    "indices_data.info()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 21,
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
   "id": "4a471f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_data['rendimentoDomiciliar'] = indices_data['rendimentoDomiciliar'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": 22,
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
   "id": "18e53d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataset tem 27 linhas e 7 colunas.\n",
      "--------------------------------------------------\n",
      "Total de colunas com registros ausentes 0\n",
      "\n",
      "Registros ausentes por coluna:\n",
      "> siglaUF, ausentes: 0 (0.00%)\n",
      "> estado, ausentes: 0 (0.00%)\n",
      "> rendimentoDomiciliar, ausentes: 0 (0.00%)\n",
      "> despesaMediaSaude, ausentes: 0 (0.00%)\n",
      "> indiceGini, ausentes: 0 (0.00%)\n",
      "> indicePalma, ausentes: 0 (0.00%)\n",
      "> area2019, ausentes: 0 (0.00%)\n",
      "--------------------------------------------------\n",
      "Total de registros duplicados 0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "verificarAusentesDuplicados(indices_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1021f03f",
   "metadata": {},
   "source": [
    "#### Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 23,
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
   "id": "6950ac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27 entries, 0 to 26\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   estado                27 non-null     object \n",
      " 1   siglaUF               27 non-null     object \n",
      " 2   casosAcumulado        27 non-null     int64  \n",
      " 3   obitosAcumulado       27 non-null     int64  \n",
      " 4   rendimentoDomiciliar  27 non-null     float64\n",
      " 5   despesaMediaSaude     27 non-null     float64\n",
      " 6   indiceGini            27 non-null     float64\n",
      " 7   indicePalma           27 non-null     float64\n",
      " 8   densidadeDemografica  27 non-null     float64\n",
      " 9   taxaLetalidade        27 non-null     float64\n",
      " 10  incidencia            27 non-null     float64\n",
      " 11  mortalidade           27 non-null     float64\n",
      "dtypes: float64(8), int64(2), object(2)\n",
      "memory usage: 2.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df1 = estados_df.groupby(\"estado\").agg(\n",
    "        {\n",
    "            \"siglaUF\":\"last\",\n",
    "            \"casosAcumulado\":\"max\",\n",
    "            \"obitosAcumulado\":\"max\",\n",
    "            \"populacaoTCU2019\":\"max\",\n",
    "        }\n",
    ").reset_index() \n",
    "\n",
    "df2 = indices_data.copy()\n",
    "\n",
    "indices_df = pd.merge(df1, df2, on=['siglaUF', 'estado'])\n",
    "indices_df[\"densidadeDemografica\"] = indices_df[\"populacaoTCU2019\"]/indices_df[\"area2019\"]\n",
    "indices_df[\"taxaLetalidade\"] = indices_df[\"obitosAcumulado\"]/indices_df[\"casosAcumulado\"]*100\n",
    "indices_df[\"incidencia\"] = indices_df[\"casosAcumulado\"]/indices_df[\"populacaoTCU2019\"]*100000\n",
    "indices_df[\"mortalidade\"] = indices_df[\"obitosAcumulado\"]/indices_df[\"populacaoTCU2019\"]*100000\n",
    "indices_df = indices_df.drop([\"area2019\", \"populacaoTCU2019\"], axis=1).reset_index(drop=True)\n",
    "indices_df.info()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 24,
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
   "id": "8a3b8604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataset tem 27 linhas e 12 colunas.\n",
      "--------------------------------------------------\n",
      "Total de colunas com registros ausentes 0\n",
      "\n",
      "Registros ausentes por coluna:\n",
      "> estado, ausentes: 0 (0.00%)\n",
      "> siglaUF, ausentes: 0 (0.00%)\n",
      "> casosAcumulado, ausentes: 0 (0.00%)\n",
      "> obitosAcumulado, ausentes: 0 (0.00%)\n",
      "> rendimentoDomiciliar, ausentes: 0 (0.00%)\n",
      "> despesaMediaSaude, ausentes: 0 (0.00%)\n",
      "> indiceGini, ausentes: 0 (0.00%)\n",
      "> indicePalma, ausentes: 0 (0.00%)\n",
      "> densidadeDemografica, ausentes: 0 (0.00%)\n",
      "> taxaLetalidade, ausentes: 0 (0.00%)\n",
      "> incidencia, ausentes: 0 (0.00%)\n",
      "> mortalidade, ausentes: 0 (0.00%)\n",
      "--------------------------------------------------\n",
      "Total de registros duplicados 0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "verificarAusentesDuplicados(indices_df)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "id": "73d05115",
   "metadata": {},
   "source": [
    "#### Salvar Dataframe resultante em um arquivo CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
=======
   "cell_type": "code",
   "execution_count": 25,
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
   "id": "8461310b",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
=======
    "# Salvar o DataFrame resultante em um arquivo CSV\n",
>>>>>>> 5f235899277fb8f0ee4b45bce750955fd4587af8
    "indices_df.to_csv(\n",
    "    os.path.join(output_data_path, 'indices_dataset.csv'), index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
